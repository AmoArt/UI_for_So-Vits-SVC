{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "# Check graphics card\n",
        "\n",
        "\n",
        "#remeber to 'cd' into another folder in the terminal before running the conection stuff\n",
        "#like 'cd D:\\colab'\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0gQcIZ8RsOkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f9130b-87a5-4de4-a135-c0f7428e9eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 17 12:09:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 473.62       Driver Version: 473.62       CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:2D:00.0  On |                  N/A |\n",
            "| 77%   38C    P2    41W / 216W |   8080MiB /  8088MiB |     10%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      3128    C+G   ...8.0.2.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A      5408    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A      8516    C+G   ...tudio\\bin\\64bit\\obs64.exe    N/A      |\n",
            "|    0   N/A  N/A     13648    C+G   ...4bit\\obs-browser-page.exe    N/A      |\n",
            "|    0   N/A  N/A     25096    C+G   ...\\Programs\\Opera\\opera.exe    N/A      |\n",
            "|    0   N/A  N/A     28544    C+G   ...iles\\VideoLAN\\VLC\\vlc.exe    N/A      |\n",
            "|    0   N/A  N/A     28556    C+G   ...ropbox\\Client\\Dropbox.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS0OPRkL4Pme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae7a30a-561d-44a3-cb51-a7b9341b3806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'so-vits-svc'...\n"
          ]
        }
      ],
      "source": [
        "#@title Clone github repo\n",
        "!git clone https://github.com/effusiveperiscope/so-vits-svc -b eff-4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "!pip install pyworld praat-parselmouth\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install fairseq==0.12.2 librosa==0.8.1"
      ],
      "metadata": {
        "id": "zXBLkXxL4T1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b873a4c7-4340-4563-a1aa-0dcff4881f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyworld\n",
            "  Using cached pyworld-0.3.2-cp310-cp310-win_amd64.whl (209 kB)\n",
            "Collecting praat-parselmouth\n",
            "  Using cached praat_parselmouth-0.4.3-cp310-cp310-win_amd64.whl (8.9 MB)\n",
            "Requirement already satisfied: numpy in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from pyworld) (1.23.5)\n",
            "Collecting cython\n",
            "  Using cached Cython-0.29.33-py2.py3-none-any.whl (987 kB)\n",
            "Installing collected packages: praat-parselmouth, cython, pyworld\n",
            "Successfully installed cython-0.29.33 praat-parselmouth-0.4.3 pyworld-0.3.2\n",
            "Requirement already satisfied: pip in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (23.0.1)\n",
            "Collecting fairseq==0.12.2\n",
            "  Using cached fairseq-0.12.2-cp310-cp310-win_amd64.whl\n",
            "Collecting librosa==0.8.1\n",
            "  Using cached librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "Requirement already satisfied: cython in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from fairseq==0.12.2) (0.29.33)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Collecting regex\n",
            "  Using cached regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
            "Collecting omegaconf<2.1\n",
            "  Using cached omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting bitarray\n",
            "  Using cached bitarray-2.7.3-cp310-cp310-win_amd64.whl (118 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from fairseq==0.12.2) (1.23.5)\n",
            "Requirement already satisfied: torch in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from fairseq==0.12.2) (1.12.0)\n",
            "Requirement already satisfied: cffi in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from fairseq==0.12.2) (0.12.0)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Using cached hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "Collecting scikit-learn!=0.19.0,>=0.14.0\n",
            "  Using cached scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
            "Collecting soundfile>=0.10.2\n",
            "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
            "Collecting pooch>=1.0\n",
            "  Using cached pooch-1.7.0-py3-none-any.whl (60 kB)\n",
            "Collecting audioread>=2.0.0\n",
            "  Using cached audioread-3.0.0-py3-none-any.whl\n",
            "Collecting resampy>=0.2.2\n",
            "  Using cached resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from librosa==0.8.1) (5.1.1)\n",
            "Collecting numba>=0.43.0\n",
            "  Using cached numba-0.56.4-cp310-cp310-win_amd64.whl (2.5 MB)\n",
            "Collecting joblib>=0.14\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from librosa==0.8.1) (23.0)\n",
            "Collecting scipy>=1.0.0\n",
            "  Using cached scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Using cached antlr4_python3_runtime-4.8-py3-none-any.whl\n",
            "Collecting llvmlite<0.40,>=0.39.0dev0\n",
            "  Using cached llvmlite-0.39.1-cp310-cp310-win_amd64.whl (23.2 MB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from numba>=0.43.0->librosa==0.8.1) (65.6.3)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from omegaconf<2.1->fairseq==0.12.2) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from pooch>=1.0->librosa==0.8.1) (2.28.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from pooch>=1.0->librosa==0.8.1) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.4.6)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting lxml\n",
            "  Using cached lxml-4.9.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
            "Collecting portalocker\n",
            "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pycparser in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2.0.4)\n",
            "Requirement already satisfied: pywin32>=226 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from portalocker->sacrebleu>=1.4.12->fairseq==0.12.2) (305)\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, tqdm, threadpoolctl, tabulate, scipy, regex, portalocker, omegaconf, lxml, llvmlite, joblib, audioread, soundfile, scikit-learn, sacrebleu, pooch, numba, hydra-core, resampy, fairseq, librosa\n",
            "Successfully installed antlr4-python3-runtime-4.8 audioread-3.0.0 bitarray-2.7.3 fairseq-0.12.2 hydra-core-1.0.7 joblib-1.2.0 librosa-0.8.1 llvmlite-0.39.1 lxml-4.9.2 numba-0.56.4 omegaconf-2.0.6 pooch-1.7.0 portalocker-2.7.0 regex-2022.10.31 resampy-0.4.2 sacrebleu-2.3.1 scikit-learn-1.2.2 scipy-1.10.1 soundfile-0.12.1 tabulate-0.9.0 threadpoolctl-3.1.0 tqdm-4.65.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir ('./so-vits-svc/')\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dsgJksUynS2",
        "outputId": "310b0c64-d0ad-49cc-ab4d-d3274c418c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'G:\\\\colab\\\\so-vits-svc'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4uc6YqCTzUF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download ContentVec model file\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "url = 'https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt'\n",
        "filename = wget.download(url)\n",
        "print(filename)"
      ],
      "metadata": {
        "id": "pCqf3W0d6ify",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165f9d18-33b2-4aea-b5ab-ee8305072a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Using cached wget-3.2-py3-none-any.whl\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "100% [................................................] 1330114945 / 1330114945checkpoint_best_legacy_500.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Backup link (in case the above do not work)\n",
        "#anonfiles.com/ScObw8d0z6/checkpoint_best_legacy_500_pt\n",
        "#^open this link in brose, right click on the download button and \"copy the adress\" to the 'url' portion below\n",
        "\n",
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://cdn-149.anonfiles.com/ScObw8d0z6/b89b1220-1678487735/checkpoint_best_legacy_500.pt'\n",
        "filename = wget.download(url)\n",
        "print(filename)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WoSPcko-z9Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Move file to hubert folder\n",
        "\n",
        "import shutil\n",
        "\n",
        "shutil.move(\"checkpoint_best_legacy_500.pt\", \"./hubert\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqGRVWXl1K-O",
        "outputId": "fbaf75b1-1e79-46e3-b618-f93e14494ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./hubert\\\\checkpoint_best_legacy_500.pt'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preprocessing"
      ],
      "metadata": {
        "id": "k1qadJBFehMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for sake of simplicity, create a folder 'dataset' and place your zip file in there and fill out the rest of this info.\n",
        "\n",
        "Alterantively, ignore this one cell, and place your stuff in \"so-vits-svc/dataset_raw/(your_character_name)/wavs_files.wav\" directory and run the resample cell.\n"
      ],
      "metadata": {
        "id": "qZARL8Io22t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the dataset from .zip in Google Drive for preprocessing\n",
        "#@markdown Name of the zip folder\n",
        "DATASETNAME = \"NamelessHero_eng\"  #@param {type:\"string\"}\n",
        "#@markdown Zip path (usually do not need to change this unless you uploaded to a different directory)\n",
        "ZIP_PATH = \"./dataset/\"  #@param {type:\"string\"}\n",
        "ZIP_NAME = ZIP_PATH + DATASETNAME\n",
        "\n",
        "!unzip -d /content/so-vits-svc/dataset_raw {ZIP_NAME}.zip"
      ],
      "metadata": {
        "id": "U05CXlAipvJR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Resample to 44.1k\n",
        "!python resample.py"
      ],
      "metadata": {
        "id": "_ThKTzYs5CfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a2e029-83d6-4d69-e324-50035a90b556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./dataset_raw\\TreeHugger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\n",
            "1it [00:15, 15.07s/it]\n",
            "9it [00:15,  1.22s/it]\n",
            "11it [00:15,  1.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Segment training set and generate configuration files\n",
        "!python preprocess_flist_config.py"
      ],
      "metadata": {
        "id": "svITReeL5N8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a13732-a9d1-4853-83b4-4edde3906c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./filelists/train.txt\n",
            "Writing ./filelists/val.txt\n",
            "Writing ./filelists/test.txt\n",
            "Writing configs/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "100%|##########| 1/1 [00:00<00:00, 499.98it/s]\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\n",
            "100%|##########| 7/7 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "100%|##########| 2/2 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "100%|##########| 2/2 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate hubert and f0\n",
        "!python preprocess_hubert_f0.py"
      ],
      "metadata": {
        "id": "xHUXMi836DMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c943cfe0-3a1c-4d3a-a0d7-4960a8b94377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11]\n",
            "Loading hubert for content...\n",
            "load model(s) from hubert/checkpoint_best_legacy_500.pt\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "INFO:fairseq.tasks.hubert_pretraining:current directory is G:\\colab\\so-vits-svc\n",
            "INFO:fairseq.tasks.hubert_pretraining:HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
            "INFO:fairseq.models.hubert.hubert:HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
            "Loaded hubert.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/11 [00:00<?, ?it/s]\n",
            "  9%|9         | 1/11 [00:15<02:31, 15.12s/it]\n",
            " 18%|#8        | 2/11 [00:15<00:56,  6.33s/it]\n",
            " 27%|##7       | 3/11 [00:15<00:27,  3.49s/it]\n",
            " 36%|###6      | 4/11 [00:15<00:15,  2.20s/it]\n",
            " 45%|####5     | 5/11 [00:15<00:08,  1.49s/it]\n",
            " 64%|######3   | 7/11 [00:16<00:03,  1.30it/s]\n",
            " 73%|#######2  | 8/11 [00:16<00:01,  1.68it/s]\n",
            " 91%|######### | 10/11 [00:16<00:00,  2.63it/s]\n",
            "100%|##########| 11/11 [00:16<00:00,  3.09it/s]\n",
            "100%|##########| 11/11 [00:16<00:00,  1.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ENoH-pShel7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  download the G_0 and D_0 models\n",
        "#anonfiles.com/GaX4w6dfz7/G_0_pth\n",
        "#anonfiles.com/m8Wew6d8z9/D_0_pth\n",
        "#^open this link in browse, right click on the download button and \"copy the adress\" to the 'url' portion below\n",
        "\n",
        "\n",
        "import wget\n",
        "#url = 'https://cdn-149.anonfiles.com/GaX4w6dfz7/4c3a0170-1678490854/G_0.pth'\n",
        "url = 'https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/G_0.pth'\n",
        "filename = wget.download(url)\n",
        "print(filename)\n",
        "#url = 'https://cdn-153.anonfiles.com/m8Wew6d8z9/2ef7633b-1678490871/D_0.pth'\n",
        "url = 'https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/D_0.pth'\n",
        "filename = wget.download(url)\n",
        "print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ccbaRGf8_RRH",
        "outputId": "97ae0c5e-bce9-4a68-8609-0e663945639e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% [..................................................] 180628517 / 180628517G_0.pth\n",
            "100% [..................................................] 187018591 / 187018591D_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  move the G_0 and D_0 models\n",
        "\n",
        "import shutil\n",
        "shutil.move(\"G_0.pth\", \".\\\\logs\\\\44k\")\n",
        "shutil.move(\"D_0.pth\", \".\\\\logs\\\\44k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChpO-AecAJfR",
        "outputId": "55e40ed7-5edf-4c44-f4df-7c5fe0450a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.\\\\logs\\\\44k\\\\D_0.pth'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEiuIpGlCe4S",
        "outputId": "5c5ca76c-23de-4472-9be1-54afe5a01ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboard\n",
            "  Using cached tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from tensorboard) (2.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from tensorboard) (65.6.3)\n",
            "Collecting grpcio>=1.48.2\n",
            "  Using cached grpcio-1.51.3-cp310-cp310-win_amd64.whl (3.7 MB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from tensorboard) (1.23.5)\n",
            "Collecting protobuf>=3.19.6\n",
            "  Using cached protobuf-4.22.1-cp310-abi3-win_amd64.whl (420 kB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Using cached google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from tensorboard) (0.38.4)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Installing collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, markdown, grpcio, cachetools, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n",
            "Successfully installed absl-py-1.4.0 cachetools-5.3.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 markdown-3.4.1 oauthlib-3.2.2 protobuf-4.22.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.3\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.7.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from matplotlib) (9.4.0)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from matplotlib) (1.23.5)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.2-py3-none-any.whl (1.0 MB)\n",
            "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.1/1.0 MB 3.2 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 0.3/1.0 MB 4.5 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 0.5/1.0 MB 4.9 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 0.8/1.0 MB 5.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.0/1.0 MB 5.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user001\\miniconda3\\envs\\colab0\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.2 kiwisolver-1.4.4 matplotlib-3.7.1 pyparsing-3.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell and cell below\n",
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyVi84ujMSYt",
        "outputId": "448b6d08-ac44-4353-fc18-f94c68cc909a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'G:\\\\colab\\\\so-vits-svc'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title python: can't open file 'G:\\\\colab\\\\train.py': [Errno 2] No such file or directory\n",
        "\n",
        "import os\n",
        "os.chdir ('./so-vits-svc/')\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8xOy0PUMZCT",
        "outputId": "0e9fcb0f-a436-4ba9-adf1-3de4962bea04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'G:\\\\colab\\\\so-vits-svc'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edit the so-vits-svc\\configs\\config.json file from batch 6 to batch 1 (as standard gaming gpus will not able to handle large batch trainings).\n",
        "\n",
        "Sadly the code is broken and will not restart from last point on its own, for restarting training, go to the 'logs/44k/ folder and move or remove all the D_ and G_ models from directory with exception for the latest ones, and rename them to D_0 and G_0.\n",
        "italicized text\n",
        "\n",
        "Than run two cells above than run the cell below.\n",
        "\n",
        "Recommeneded to train the model in one go."
      ],
      "metadata": {
        "id": "7dzTUAG7PjqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Start training\n",
        "#@markdown **Start training**\n",
        "Clone = \"44k\"\n",
        "\n",
        "#@markdown **Enable tensorboard for data visualization (dont turn it on, tensorboard seems to be broken here)**\n",
        "tensorboard_on = False #@param {type:\"boolean\"}\n",
        "if tensorboard_on:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir logs\\\"{Clone}\"\n",
        "\n",
        "!python train.py -c configs/config.json -m \"{Clone}\"\n"
      ],
      "metadata": {
        "id": "-hEFFTCfZf57",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cadac8-dd88-4e66-95ae-3c780e00cfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    }
  ]
}